
Studio Edge has a variety of client applications that perform file uploads of scripts, images, and other resources through [DGS]es.
In [GraphQL], you model a file upload operation as a GraphQL mutation request from a client to your DGS.

The following sections describe how you implement file uploads and downloads.
You use one of the following two approaches, depending on whether the file upload query goes directly to your DGS from a client, or it goes to your DGS through the [gateway]:

* multipart upload requests for file transfers direct to DGS (not through the gateway)
* pre-signed URLs generated by your DGS for file transfer queries that are part of the [federated] graph

!!!tip
    For more context on file uploads and best practices, see [Apollo Server File Upload Best Practices](https://www.apollographql.com/blog/apollo-server-file-upload-best-practices-1e7f24cdc050) by Khalil Stemmler from *Apollo Blog*.

## Multipart File Upload

A multipart request is an HTTP request that contains multiple parts in a single request: the mutation query, file data, JSON objects, and whatever else you like.
You can use Apollo’s upload client, or even a simple cURL, to send along a stream of file data using a multipart request that you model in your schema as a Mutation.

![File uploads with multipart](../../../img/file-upload-multipart.png#center)

!!!info
    See [GraphQL multipart request specification](https://github.com/jaydenseric/graphql-multipart-request-spec) for the specification of a multipart `POST` request for uploading files using GraphQL mutations.

The DGS framework supports the `Upload` scalar with which you can specify files in your mutation query as a `MultipartFile`.
When you send a multipart request for file upload, the framework processes each part and assembles the final GraphQL query that it hands to your data fetcher for further processing.

Here is an example of a Mutation query that uploads a file to your DGS:

```graphql
""" For uploads using multi-part POST only. DO NOT include in federated scheme registered with gateway!!"""
scalar Upload

extend type Mutation  {
    uploadScriptWithMultipartPOST(input: Upload!): Boolean
}
```

Note that you need to declare the `Upload` scalar in your schema, although the implementation is provided by the DGS framework.
Also, if you register the graph that your DGS implements with the gateway, you must exclude the file upload parts of the schema (the `Upload` scalar and your Mutation query) from the schema that you publish to the [schema registry].
You can do this by separating those parts of the schema into a separate schema file and by not adding that file to your list of schema files to publish when you configure your [schema validation plugin](https://manuals.netflix.net/view/studioedge/mkdocs/master/workflow/update/#tools-for-schema-updates).

In your DGS, add a data fetcher to handle this as a `MultipartFile` as shown here:

```java
@DgsData(parentType = DgsConstants.MUTATION.TYPE_NAME, field = "uploadScriptWithMultipartPOST")
    public boolean uploadScript(DataFetchingEnvironment dfe) throws IOException {
        // NOTE: Cannot use @InputArgument  or Object Mapper to convert to class, because MultipartFile cannot be
        // deserialized
        MultipartFile file = dfe.getArgument("input");
        String content = new String(file.getBytes());
        return ! content.isEmpty();
    }

```

Note that you will not be able to use a Jackson object mapper to deserialize a type that contains a `MultipartFile`, so you will need to explicitly get the file argument from your input.

On your client, you can use `apollo-upload-client` to send your Mutation query as a multipart `POST` request with file data.
Here’s how you configure your link:

```javascript
import { createUploadLink } from 'apollo-upload-client'

const uploadLink = createUploadLink({ uri: uri })

const authedClient = authLink && new ApolloClient({
        link: uploadLink)),
        cache: new InMemoryCache()
})
```

Once you set this up, set up your Mutation query and the pass the file that the user selected as a variable:

```javascript
// query for file uploads using multipart post
const UploadScriptMultipartMutation_gql = gql`
  mutation uploadScriptWithMultipartPOST($input: Upload!) {
    uploadScriptWithMultipartPOST(input: $input)
  }
`;

function MultipartScriptUpload() {
  const [
    uploadScriptMultipartMutation,
    {
      loading: mutationLoading,
      error: mutationError,
      data: mutationData,
    },
  ] = useMutation(UploadScriptMultipartMutation_gql);
  const [scriptMultipartInput, setScriptMultipartInput] = useState<any>();

  const onSubmitScriptMultipart = () => {
    const fileInput = scriptMultipartInput.files[0];
    uploadScriptMultipartMutation({
      variables: { input: fileInput },
    });
  };

  return (
    <div>
      <h3> Upload script using multipart HTTP POST</h3>
      <form
        onSubmit={e => {
          e.preventDefault();
          onSubmitScriptMultipart();
        }}>
        <label>
          <input
            type="file"
            ref={ref => {
              setScriptMultipartInput(ref!);
            }}
          />
        </label>
        <br />
        <br />
        <button type="submit">Submit</button>
      </form>
    </div>
  );
}
```

For a complete example, see [`ScriptUploadMultipartPOST.tsx`](https://stash.corp.netflix.com/projects/PX/repos/file-uploads-example-ui/browse/src/lib/components/ScriptUploadMultipartPOST.tsx) from the `file-uploads-example-ui` project.

!!!caution "Important"
    This mechanism is not supported by the Studio Edge Gateway and you should use it only for uploading files directly to the DGS from the client.
    To do this, you must configure your DGS so that your client can talk to it through [Wall-E].

## Uploading and Downloading Files Using Presigned URLs

When you implement file mutation queries that will be part of the federated graph, we recommend that you use pre-signed URLs.
A pre-signed URL is an authenticated URL that your DGS can generate and return to the client, based on filename, sender, etc.
The client uses this URL to upload files to, or download files from, the file storage service directly.
This avoids streaming data through the gateway, and is the preferred method to avoid affecting the performance of the gateway.

![File uploads with presigned URLS](../../../img/file-upload-presigned.png)

The pre-signed URL flow follows this sequence:

1. The client sends to the DGS a Mutation query that specifies the file name.
   This query may or may not contain additional metadata to be handled by the DGS. 
2. The DGS authorizes the query based on the DGS [AuthZ] policies.
   It requests a signed token from a file storage service (e.g., Baggins) based on the requestor’s email and the file name.
3. The DGS responds to the client with the presigned URL (represented as a `PresignedUrlResponse` which is available as a common type).
4. The client uploads or downloads files to the file storage service by using the URL in the response. 
5. The DGS can asynchronously monitor the status of the file upload operation.
6. Once the upload is complete, the DGS can operate on additional metadata, and/or download the file for post-processing once the upload is complete.

At this point, the client can send additional metadata if it did not do so already as part of the initial request.
The client can also query the DGS to determine the success of the operation using a separate status update query specifying the `uploadID`, if one is returned by the DGS.

To maintain consistency across clients, implement the following interface for the response containing pre-signed URLs:

```graphql
"""
Representation of a response to a request for file upload or download containing a URL.
"""
interface PresignedUrlResponse {
    """
    A pre-signed file URL for uploads and downloads generated using a backend service.
    """
    url: String
    """
    The custom headers that need to be set by the client in the upload/download request.
    """
    headers: [Header]
    """
    The method, e.g., POST, to use for uploading or downloading files using the URL.
    """
    method: String
}

"""
Representation of an HTTP request header with name of the header and the value.
"""
type Header {
    """
    The name of the header.
    """
    name: String
    """
    The value of the header.
    """
    value: String
}
```

This interface is  available in common types library, so you  only need to add an implementation in your application.


The following sections describe the preferred way to use pre-signed URLs with a sample DGS and React application.
For file storage, we recommend using [Baggins](https://docs.google.com/document/d/1GroN4CMUrt8KaHV99a5SdOfLuKnAx6H0C7K5IWLKMj8/edit#heading=h.esicatn7ril0), which is a Netflix-maintained file storage service that provides encryption on top of S3.

!!!tip
    For more information on Baggins, see the [Baggins Architecture](https://docs.google.com/presentation/d/14GVxjm8UMpRxLRmb1hukj8fW5sHbdXNYKVyDGAXlAeE/edit#slide=id.g5c27786c0b_1_342) slide deck.

You can use Baggins for the paved-path experience, or you can choose any other file storage service such as Google Drive to suit your needs.

!!!note
    None of these design choices are built in to the DGS framework, so you can implement a solution based on your application’s requirements.  

### Set up Baggins

First, set up your keyspace (S3 bucket) where your files will be stored in Baggins for your application.
You can contact the Baggins team ([#mce-baggins](https://slack.com/app_redirect?channel=mce-baggins)) to help you with the setup.
You will need a [Gandalf] policy that specifies access policies.
We<!-- http://go/we --> recommend that this policy be the same as your DGS Gandalf policy.
The default DGS policy provides access to all Netflix employees.

Next, configure your Baggins client.
The example illustrated here uses the Baggins [gRPC] client to request for signed URLs.
Add the following dependency to your `build.gradle`:

```groovy
// Baggins gRPC client
compile 'com.netflix.baggins:baggins-client-grpc-spring:latest.release'
compile 'com.netflix.spring:spring-boot-netflix-grpc-client-annotation:latest.release'
```

You can use the gRPC client to request pre-signed URLs, as shown for example in [`BagginsService.java`](https://stash.corp.netflix.com/projects/PX/repos/file-uploads-example-dgs/browse/src/main/java/com/netflix/fileuploadsexampledgs/service/BagginsService.java) from the `file-uploads-example-dgs` project.

### Sample Schema

Next, set up the schema as shown below by modeling file uploads as a Mutation query with some metadata.

```graphql
type Mutation @extends {
    uploadScriptWithPresignedUrl(input: UploadScriptRequestInput): PresignedUrlResponse
}

input UploadScriptRequestInput {
    name: String
    description: String
    filePath: String
    fileSize: Int
}

type UploadScriptResponse implements PresignedUrlResponse {
    url: String
    headers: [Header]
    method: String
    uploadId: ID
}
```

### Set up a resolver
You will also need to set up a type resolver for the `PresignedUrlResponse` interface that you have implemented. 
Here is an example:

```java
@DgsTypeResolver(name = "PresignedUrlResponse")
    public String resolvePresignedUrlResponse(PresignedUrlResponse response) {
        if (response instanceof UploadScriptResponse) {
            return "UploadScriptResponse";
        } else {
            throw new RuntimeException("Invalid type: " + response.getClass().getName() + " found in PresignedUrlResponseResolver");
        }
    }
```

### DGS Data Fetcher

Your data fetcher in your DGS handles the above Mutation query by generating or requesting a pre-signed URL from Baggins, as shown here:

```java
    @DgsData(parentType = DgsConstants.MUTATION.TYPE_NAME, field = "uploadScriptWithPresignedUrl")
    public UploadScriptResponse uploadScript(@InputArgument("input") UploadScriptRequestInput uploadRequest, DataFetchingEnvironment dataFetchingEnvironment) throws IOException {
        BagginsService.GetTokenResponse response = bagginsService.getSignedUploadUrl(uploadRequest.getFilePath());
        CompletableFuture<Void> future = CompletableFuture.runAsync(() -> {
            long timeout = 600000;
            long startTime = System.currentTimeMillis();
            long elapsed = startTime;
            boolean status = false;
            while (!status && elapsed - startTime < timeout) {
                try {
                    TimeUnit.SECONDS.sleep(10);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                status = bagginsService.checkFileUploadStatus(response.keyname);
                elapsed = System.currentTimeMillis() - startTime;
            }
            if (elapsed - startTime >= timeout) {
                logger.error("Encountered a timeout waiting for file %s to upload", response.keyname);
            }

            // You can perform your post upload actions at this point - e.g., download the file for post processing
            // or process meta data
            try {
                bagginsService.downloadFile(response.keyname);
            } catch (IOException e) {
                e.printStackTrace();
            }
        });

        Integer fileSize = uploadRequest.getFileSize();
        PresignedUrlResponse.Header header1 = new PresignedUrlResponse.Header();
        header1.setName("Content-Type");
        header1.setValue("application/octet-stream");
        PresignedUrlResponse.Header header2 = new PresignedUrlResponse.Header();
        header2.setName("x-baggins-upload-file-length");
        header2.setValue(fileSize.toString());
        List<PresignedUrlResponse.Header> headers =
                new ArrayList<>(Arrays.asList(header1, header2));

        return new UploadScriptResponse( response.token, headers, "POST", response.keyname);
    }

```

To ensure consistency from a client perspective for file uploads and downloads, we<!-- http://go/we --> recommend the following:

1. Set up a `CompletableFuture` to poll on the status of the file upload by the client.
   Upon completion, carry out any post-processing, such as updating metadata or downloading the file for validation, etc.
2. The client can check the status of the mutation operation (including metadata updates, etc.) via a separate status query.
3. The input arguments can contain the header-specific information, such as the file size in case of using Baggins.
   The client can set these headers without having to know about the details of the file storage service.
   From the client perspective it is a URL to upload the file to, and any additional information (such as the headers and HTTP method to use) are opaque to the client.

### Client Example

In your client application, set up your Mutation query to request a pre-signed URL from the DGS.
The client can use this URL to upload files directly to Baggins.
After file uploads complete, the client can issue a subsequent query to the DGS if the client needs to check on the status of the mutation operation.
For simple use cases, the client could just fire and forget.
Such a second status query can be useful to the client in scenarios involving post-processing of the file by the DGS, such as validation of the file, or updating metadata in another service, e.g. `Amsterdam`.

Here is an example client implementation showing the set up of queries in the UI application:

```javascript
// query for file uploads using pre-signed urls
const PresignedUrlDetails_gql = gql`
  fragment PresignedUrlDetails on PresignedUrlResponse {
    url
    headers {
      name
      value
    }
    method
  }
`;
const UploadScriptRequestMutation_gql = gql`
  mutation uploadScriptWithPresignedUrl(
    $input: UploadScriptRequestInput
  ) {
    uploadScriptWithPresignedUrl(input: $input) {
      ...PresignedUrlDetails
    }
  }
  ${PresignedUrlDetails_gql}
`;

function ScriptUploadWithPresignedURL() {
  const [
    scriptUpload,
    {
      loading: mutationLoading,
      error: mutationError,
      data: mutationData,
    },
  ] = useMutation(UploadScriptRequestMutation_gql);
  const [scriptInput, setScriptInput] = useState<HTMLInputElement>();

  type Header = {
    name: string;
    value: string;
  };

  const uploadToUrl = (
    url: string,
    headers: [Header],
    method: string,
    id: string,
    fileElement: HTMLInputElement
  ) => {
    if (
      fileElement.type !== 'file' &&
      fileElement.files!.length <= 0
    ) {
      console.log('Incorrect type of file input');
      return false;
    }

    const requestHeaders: HeadersInit = new Headers();
    headers.forEach(iter => {
      requestHeaders.set(iter.name, iter.value);
    });
    fetch(url, {
      method: method,
      headers: requestHeaders,
      body: fileElement.files![0],
    })
      .then(result => {
        console.log(`Response from baggins ${result}`);
      })
      .catch(error => {
        alert(`ERROR ${JSON.stringify(error)}`);
        console.log(`Received error ${JSON.stringify(error)}`);
      });
  };

  useEffect(() => {
    if (mutationData) {
      uploadToUrl(
        mutationData.uploadScriptWithPresignedUrl.url,
        mutationData.uploadScriptWithPresignedUrl.headers,
        mutationData.uploadScriptWithPresignedUrl.method,
        mutationData.uploadScriptWithPresignedUrl.uploadId,
        scriptInput!
      );
    }
  }, [mutationData, scriptInput]);

  const onSubmitScriptPresigned = () => {
    const path = `${scriptInput!.files![0].name}`;
    const size = scriptInput!.files![0].size;
    scriptUpload({
      variables: {
        input: {
          name: 'kavitha',
          description: 'script upload',
          filePath: path,
          fileSize: size,
        },
      },
    });
  };
}
```

The complete example is available in [`ScriptUploadWithPresignedURL.tsx`](https://stash.corp.netflix.com/projects/PX/repos/file-uploads-example-ui/browse/src/lib/components/ScriptUploadWithPresignedURL.tsx) from the `file-uploads-example-ui` project.

--8<-- "docs/reference_links"

